{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Timestamp\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "from datetime import datetime\n",
    "import re\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from collections import Counter\n",
    "from ast import literal_eval\n",
    "import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from lime import lime_text\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from lime.lime_text import LimeTextExplainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords.extend(('depression', 'depressive', 'depressed', 'anxiety', 'anxious', \n",
    "                      'suicide', 'suicidal', 'bipolar', 'bi', 'polar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(stop_words = stopwords,\n",
    "                                                             sublinear_tf = True, \n",
    "                                                             analyzer = 'word',\n",
    "                                                             token_pattern = r'\\w{2,}',\n",
    "                                                             ngram_range = (1, 3),\n",
    "                                                             max_features = 25000\n",
    "                                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T09:27:35.774751Z",
     "start_time": "2020-05-21T09:27:35.699132Z"
    }
   },
   "outputs": [],
   "source": [
    "c = make_pipeline(vectorizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T09:27:38.454809Z",
     "start_time": "2020-05-21T09:27:38.449603Z"
    }
   },
   "outputs": [],
   "source": [
    "explainer = LimeTextExplainer(class_names=model.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T07:56:15.633952Z",
     "start_time": "2020-05-21T07:56:15.620612Z"
    }
   },
   "outputs": [],
   "source": [
    "model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T22:03:21.132859Z",
     "start_time": "2020-05-20T22:03:20.991462Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T22:03:31.500293Z",
     "start_time": "2020-05-20T22:03:31.388114Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = pd.concat([X_test, y_test], axis=1)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T22:03:40.768597Z",
     "start_time": "2020-05-20T22:03:40.501605Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = test.iloc[:, [0, -1]]\n",
    "train = train.iloc[:, [0, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T09:00:29.358655Z",
     "start_time": "2020-05-21T08:45:07.196565Z"
    }
   },
   "outputs": [],
   "source": [
    "train_vectors = vectorizer.fit_transform(train.text)\n",
    "test_vectors = vectorizer.transform(test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T22:07:25.134060Z",
     "start_time": "2020-05-20T22:07:25.128225Z"
    }
   },
   "outputs": [],
   "source": [
    "train.subreddit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T09:26:09.992754Z",
     "start_time": "2020-05-21T09:01:22.624971Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LR.fit(train_vectors, train.subreddit)\n",
    "print('model done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T11:06:26.146737Z",
     "start_time": "2020-05-21T11:06:22.921734Z"
    }
   },
   "outputs": [],
   "source": [
    "idx = 360\n",
    "print(test.text.iloc[idx])\n",
    "exp = explainer.explain_instance(test.text.iloc[idx], c.predict_proba, num_features=6, top_labels=4)\n",
    "\n",
    "print() \n",
    "exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T10:47:18.911449Z",
     "start_time": "2020-05-21T10:47:15.705622Z"
    }
   },
   "outputs": [],
   "source": [
    "idx = 15244\n",
    "print(test.text.iloc[idx])\n",
    "exp = explainer.explain_instance(test.text.iloc[idx], c.predict_proba, num_features=6, top_labels=4)\n",
    "\n",
    "print()\n",
    "exp.show_in_notebook(text=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
